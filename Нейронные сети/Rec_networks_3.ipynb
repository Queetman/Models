{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Возьмите англо-русскую пару фраз (https://www.manythings.org/anki/)\n",
        "Обучите на них seq2seq по аналогии с занятием. Оцените полученное качество\n",
        "Попробуйте добавить +1 рекуррентный слой в encoder и decoder\n",
        "Попробуйте заменить GRU ячейки на lstm-ячейки\n",
        "Оцените качество во всех случаях\n",
        "*5. Добавит в лекционный ноутбук, в функцию train, обучение батчами."
      ],
      "metadata": {
        "id": "kvtLgzMCF-fb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YlRH3mQM9tf"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIEGXF8oM9tt"
      },
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/rus-eng.zip\n",
        "!unzip rus-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sM5SxbpIggK",
        "outputId": "9cb223af-8486-426a-b06d-e1222b2f3c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-23 11:13:40--  https://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16305013 (16M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  15.55M  46.0MB/s    in 0.3s    \n",
            "\n",
            "2024-12-23 11:13:41 (46.0 MB/s) - ‘rus-eng.zip’ saved [16305013/16305013]\n",
            "\n",
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail rus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIxQSOuZJUB-",
        "outputId": "2ee8fdf1-889c-4f8c-a02e-dc30ab8f1538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (BHO) & #6390439 (odexed)\n",
            "I've heard that you should never date anyone who is less than half your age plus seven. Tom is now 30 years old and Mary is 17. How many years will Tom need to wait until he can start dating Mary?\tЯ слышал, что никогда не следует встречаться с кем-то вдвое младше вас плюс семь лет. Тому 30 лет, a Мэри 17. Сколько лет Тому нужно ждать до тех пор, пока он сможет начать встречаться с Мэри?\tCC-BY 2.0 (France) Attribution: tatoeba.org #10068197 (CK) & #10644473 (notenoughsun)\n",
            "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (BHO) & #6390123 (odexed)\n",
            "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (BHO) & #5968115 (odexed)\n",
            "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
            "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (BHO) & #4509418 (odexed)\n",
            "When I was younger, I hated going to weddings. My grandmothers and aunts would huddle around me, poke me in the side, and giggle \"You're next! You're next!\" They only stopped this nonsense when I began to do the same thing at funerals.\tКогда я была помоложе, я ненавидела ходить на свадьбы. Мои бабушки и тётки толпились вокруг, тыкали меня в бок и говорили, посмеиваясь: «Ты следующая! Ты следующая!». Они перестали нести этот вздор только тогда, когда я начала делать то же самое на похоронах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2776770 (AlanF_US) & #4311406 (odexed)\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
            "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
            "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head rus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTF3lZahLBhm",
        "outputId": "295e0533-5a69-48e7-cfec-aa60b3090e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tМарш!\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1159202 (shanghainese)\n",
            "Go.\tИди.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #5898247 (marafon)\n",
            "Go.\tИдите.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #5898250 (marafon)\n",
            "Hi.\tЗдравствуйте.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #402127 (odexed)\n",
            "Hi.\tПривет!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #466968 (katjka)\n",
            "Hi.\tХай.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #467233 (timsa)\n",
            "Hi.\tЗдрасте.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #3803577 (marafon)\n",
            "Hi.\tЗдоро́во!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #3854188 (marafon)\n",
            "Hi.\tПриветик!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #7234283 (marafon)\n",
            "Run!\tБеги!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #1569978 (Biga)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы сделать то что было на олекции, сначалал нжно подготовить данные: удалить лишние столбцы."
      ],
      "metadata": {
        "id": "0o4OD2EUR4ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('rus.txt', sep ='\\t', header=None)\n",
        "df = df.iloc[:, :2]\n",
        "df = df.iloc[::10] # берем каждое 10 значение.\n",
        "df = df.reset_index(drop=True)\n",
        "df.head()\n",
        "df.to_csv('rus.txt', index=False, header=False, sep='\\t') # запись  в то же файл"
      ],
      "metadata": {
        "id": "dUWZ5yaJLabQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "oqfwAVZ6OT3k",
        "outputId": "94fced6d-faaa-427c-b48b-0f2e1b3e59f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0          1\n",
              "0    Go.      Марш!\n",
              "1   Run!    Бегите!\n",
              "2  Duck!  Пригнись!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47fde66d-5852-41cb-ad8b-563ca2c5a4f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Марш!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Бегите!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Duck!</td>\n",
              "      <td>Пригнись!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47fde66d-5852-41cb-ad8b-563ca2c5a4f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47fde66d-5852-41cb-ad8b-563ca2c5a4f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47fde66d-5852-41cb-ad8b-563ca2c5a4f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3f590000-715c-49d9-9eb4-565db3a252ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f590000-715c-49d9-9eb4-565db3a252ad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3f590000-715c-49d9-9eb4-565db3a252ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 49606,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49509,\n        \"samples\": [\n          \"We don't know for sure.\",\n          \"I'm trying to figure out what to do next.\",\n          \"Everyone received enough food and clothing.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 48898,\n        \"samples\": [\n          \"\\u041a\\u0442\\u043e \\u0438\\u0437 \\u043d\\u0430\\u0441 \\u0432\\u0430\\u043c \\u0431\\u043e\\u043b\\u044c\\u0448\\u0435 \\u043d\\u0440\\u0430\\u0432\\u0438\\u0442\\u0441\\u044f?\",\n          \"\\u0412\\u044b \\u043d\\u0435 \\u043f\\u0440\\u0438\\u043d\\u0435\\u0441\\u0451\\u0442\\u0435 \\u043c\\u043d\\u0435 \\u0447\\u0435\\u0433\\u043e-\\u043d\\u0438\\u0431\\u0443\\u0434\\u044c \\u0432\\u044b\\u043f\\u0438\\u0442\\u044c?\",\n          \"\\u041f\\u043e\\u0436\\u0430\\u043b\\u0443\\u0439\\u0441\\u0442\\u0430, \\u0441\\u043a\\u0430\\u0436\\u0438 \\u044d\\u0442\\u043e \\u0435\\u0449\\u0451 \\u0440\\u0430\\u0437 \\u043f\\u043e-\\u0444\\u0440\\u0430\\u043d\\u0446\\u0443\\u0437\\u0441\\u043a\\u0438.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyNnJyruM9t1"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXKs8j4bM9t6"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?А-Яа-я]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_QbsJjDGms-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = open('rus.txt', encoding='utf-8').read().split('\\n')\n",
        "lines[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6yCgryfuoVL_",
        "outputId": "1b293684-9da1-47fa-bd05-7b2e01844821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Go.\\tМарш!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines[len(lines)-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_jRIcqxO19gH",
        "outputId": "07ccf2fc-67c9-4d91-c889-83349cc5ef65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines[len(lines)-2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pgWZld3s2Gz5",
        "outputId": "1d95eff4-deda-4cd6-95af-77300bd70bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I've heard that you should never date anyone who is less than half your age plus seven. Tom is now 30 years old and Mary is 17. How many years will Tom need to wait until he can start dating Mary?\\tЯ слышал, что никогда не следует встречаться с кем-то вдвое младше вас плюс семь лет. Тому 30 лет, a Мэри 17. Сколько лет Тому нужно ждать до тех пор, пока он сможет начать встречаться с Мэри?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8T4VxZeM9t-"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('rus.txt', encoding='utf-8').read().split('\\n')\n",
        "    lines.pop() # удаление последнего индекса =''\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[['j ai ans .', 'i m .'],\n",
        " ['je vais bien .', 'i m ok .'],\n",
        " ['ca va .', 'i m ok .'], что на выходе должно получиться."
      ],
      "metadata": {
        "id": "x8Yd6faINmNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " input_lang, output_lang, pairs = readLangs('rus','eng', True)\n",
        "pairs[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0T-4wqvML9u",
        "outputId": "916e5d78-ef37-4a75-ccec-37050c99aff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['марш !', 'go .'],\n",
              " ['бегите !', 'run !'],\n",
              " ['пригнись !', 'duck !'],\n",
              " ['спрячьтесь .', 'hide .'],\n",
              " ['остановитесь !', 'stop !']]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBOwgEBdM9uB"
      },
      "source": [
        "MAX_LENGTH = 10 # вводим ограничение на длину предложения не больше 10\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbSDoYZbwLFV",
        "outputId": "a730bf71-c5f4-413c-d431-cd39314811a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49606"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs[len(pairs)-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHleIPZT0qKb",
        "outputId": "dc18341e-1679-4c5d-939c-a7fc5dcc0d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['я слышал что никогда не следует встречаться с кем то вдвое младше вас плюс семь лет . тому лет a мэри . сколько лет тому нужно ждать до тех пор пока он сможет начать встречаться с мэри ?',\n",
              " 'i ve heard that you should never date anyone who is less than half your age plus seven . tom is now years old and mary is . how many years will tom need to wait until he can start dating mary ?']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dZOGjd5M9uE",
        "outputId": "7935f234-6a10-42b0-868c-0f384040cc83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'ru', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 49606 sentence pairs\n",
            "Trimmed to 40903 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "ru 18191\n",
            "eng 7322\n",
            "['я сделал это когда был пьян .', 'i did that when i was drunk .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgtWqznCM9uH"
      },
      "source": [
        "The Encoder\n",
        "-----------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9vm9QBWM9uI"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwLTlgSyM9uK"
      },
      "source": [
        "The Decoder\n",
        "-----------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFbuUL1LM9uL"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6gGPtXFM9uQ"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fn8VDv8M9uS"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKsdwPmSM9uU"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_z_k5IiM9uX"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JXG-RzCM9uZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bxf45h6M9ud"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qUmQIGwM9uf"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FiqIVhiCXIKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_56t10oM9uh",
        "outputId": "87dc774b-b700-441e-9cd0-e29020e4e23f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 75000, print_every=5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 22s (- 19m 20s) (5000 6%) 4.3197\n",
            "2m 36s (- 16m 55s) (10000 13%) 3.8284\n",
            "3m 50s (- 15m 20s) (15000 20%) 3.5465\n",
            "5m 8s (- 14m 9s) (20000 26%) 3.3271\n",
            "6m 22s (- 12m 45s) (25000 33%) 3.1664\n",
            "7m 42s (- 11m 33s) (30000 40%) 3.0510\n",
            "8m 55s (- 10m 11s) (35000 46%) 2.9064\n",
            "10m 8s (- 8m 52s) (40000 53%) 2.7920\n",
            "11m 22s (- 7m 35s) (45000 60%) 2.7811\n",
            "12m 36s (- 6m 18s) (50000 66%) 2.6911\n",
            "13m 54s (- 5m 3s) (55000 73%) 2.6321\n",
            "15m 7s (- 3m 46s) (60000 80%) 2.5842\n",
            "16m 21s (- 2m 31s) (65000 86%) 2.5017\n",
            "17m 35s (- 1m 15s) (70000 93%) 2.4412\n",
            "18m 49s (- 0m 0s) (75000 100%) 2.4223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoEylSyM9uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505d1f96-4b0f-442a-8fc0-05bd10503b15"
      },
      "source": [
        "evaluateRandomly(encoder1, decoder1) # предсказывает отдельные слова, но не всегда хорошо."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> я люблю их обоих .\n",
            "= i love both of them .\n",
            "< i love them them . <EOS>\n",
            "\n",
            "> несчастныи случаи произошел на этом перекрестке .\n",
            "= the accident happened at that intersection .\n",
            "< the the is the to . . <EOS>\n",
            "\n",
            "> том не может произнести фамилию мэри .\n",
            "= tom can t pronounce mary s last name .\n",
            "< tom didn t want mary to mary . . <EOS>\n",
            "\n",
            "> мне жаль что я не могу тебе помочь .\n",
            "= i regret that i can t help you .\n",
            "< i wish i can t trust you you . .\n",
            "\n",
            "> мы даже не знаем где мы .\n",
            "= we don t even know where we are .\n",
            "< we even know where we are . . <EOS>\n",
            "\n",
            "> мои сын всего лишь подросток .\n",
            "= my son is only a teenager .\n",
            "< my son is a son . <EOS>\n",
            "\n",
            "> мне сегодня немного грустно .\n",
            "= i m feeling a little sad today .\n",
            "< i have a little bit today . <EOS>\n",
            "\n",
            "> я вас за это не прощу .\n",
            "= i won t forgive you for this .\n",
            "< i m sorry i won t do it . <EOS>\n",
            "\n",
            "> хорошо что вы не поехали .\n",
            "= it was good that you didn t go .\n",
            "< i hope you re t good good well . <EOS>\n",
            "\n",
            "> расскажи мне немного о себе .\n",
            "= tell me a bit about yourself .\n",
            "< tell me a little about . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте добавить +1 рекуррентный слой в encoder и decoder"
      ],
      "metadata": {
        "id": "aUEMiZJRWtRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru1 = nn.GRU(hidden_size, hidden_size)\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size)# добавим еще слой\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "\n",
        "\n",
        "        output, hidden = self.gru1(output, hidden) #1 проход\n",
        "        output, hidden = self.gru2(output, hidden) # 2 проход\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "8PmXNKUFXNsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru1 = nn.GRU(hidden_size, hidden_size)\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size) # добавим еще слой\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        # Прямой проход через первый GRU\n",
        "        output, hidden = self.gru1(output, hidden)\n",
        "\n",
        "        # Прямой проход через второй GRU\n",
        "        output, hidden = self.gru2(output, hidden)\n",
        "\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "8nve-VeqXRus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQtuN9wOYNDo",
        "outputId": "44a41aa4-ebc1-4a45-f58b-e78711361db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2m 4s (- 29m 6s) (5000 6%) 4.4289\n",
            "4m 4s (- 26m 30s) (10000 13%) 4.1321\n",
            "6m 1s (- 24m 6s) (15000 20%) 3.9614\n",
            "7m 57s (- 21m 52s) (20000 26%) 3.8162\n",
            "9m 54s (- 19m 49s) (25000 33%) 3.6221\n",
            "11m 51s (- 17m 46s) (30000 40%) 3.4856\n",
            "13m 48s (- 15m 47s) (35000 46%) 3.3280\n",
            "15m 45s (- 13m 47s) (40000 53%) 3.2283\n",
            "17m 41s (- 11m 47s) (45000 60%) 3.1368\n",
            "19m 38s (- 9m 49s) (50000 66%) 3.0439\n",
            "21m 34s (- 7m 50s) (55000 73%) 2.9489\n",
            "23m 31s (- 5m 52s) (60000 80%) 2.8689\n",
            "25m 27s (- 3m 55s) (65000 86%) 2.8408\n",
            "27m 24s (- 1m 57s) (70000 93%) 2.7878\n",
            "29m 20s (- 0m 0s) (75000 100%) 2.7025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Попробуйте заменить GRU ячейки на lstm-ячейки"
      ],
      "metadata": {
        "id": "2y2zMmfvZlvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, decoder1) # потери больше чем в пред. модели. По виду модели видно, что качество ниже."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D4cjGW1hMzO",
        "outputId": "53a797af-5b95-4172-a036-7bb1e377f596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> я готова .\n",
            "= i am ready .\n",
            "< i m a . <EOS>\n",
            "\n",
            "> я был очень очень счастлив .\n",
            "= i was very very happy .\n",
            "< i was very very . . . <EOS>\n",
            "\n",
            "> я устал и мне было холодно .\n",
            "= i was tired and cold .\n",
            "< i was t to to me to . . <EOS>\n",
            "\n",
            "> у тебя есть во что переодеться ?\n",
            "= do you have anything to change into ?\n",
            "< do you have anything you have ? ? ? <EOS>\n",
            "\n",
            "> когда то здесь был большои парк .\n",
            "= there used to be a large park here .\n",
            "< it was be here here . here . <EOS>\n",
            "\n",
            "> том смотрит хоккеиныи матч .\n",
            "= tom is watching a hockey game .\n",
            "< tom is going to be a . . <EOS>\n",
            "\n",
            "> у вас есть с собои авторучка ?\n",
            "= do you have a fountain pen with you ?\n",
            "< do you have a bike ? <EOS>\n",
            "\n",
            "> вам нужно перезагрузить компьютер .\n",
            "= you need to restart your computer .\n",
            "< you need to be a . . . <EOS>\n",
            "\n",
            "> я тебе надоел всем этим ?\n",
            "= am i boring you with all this ?\n",
            "< did i tell you that for this ? <EOS>\n",
            "\n",
            "> я знаю обоих братьев тома .\n",
            "= i know both of tom s brothers .\n",
            "< i know tom s tom . tom . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, (hidden, cell) = self.lstm(embedded, hidden)  # Передаем кортеж состояний\n",
        "        return output, (hidden, cell)\n",
        "\n",
        "    def initHidden(self):\n",
        "        hidden = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        cell = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        return (hidden, cell)"
      ],
      "metadata": {
        "id": "i7P_PPaBZoFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)  # Заменили GRU на LSTM\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "\n",
        "        # Передаем скрытое состояние и состояние ячейки\n",
        "        output, (hidden, cell) = self.lstm(output, hidden)  # Передаем кортеж состояний\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, (hidden, cell)  # Возвращаем оба состояния\n",
        "\n",
        "    def initHidden(self):\n",
        "        # Инициализация скрытого состояния и состояния ячейки\n",
        "        hidden = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        cell = torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        return (hidden, cell)  # Возвращаем кортеж из скрытого состояния и состояния ячейки"
      ],
      "metadata": {
        "id": "WsyB6-M_Z629"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-Tos-tvhhEy",
        "outputId": "3f766ce9-76e7-4efb-dff1-4fd2100f3148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 24s (- 19m 48s) (5000 6%) 4.4241\n",
            "2m 45s (- 17m 57s) (10000 13%) 3.9962\n",
            "4m 8s (- 16m 32s) (15000 20%) 3.7641\n",
            "5m 30s (- 15m 9s) (20000 26%) 3.5611\n",
            "6m 52s (- 13m 44s) (25000 33%) 3.4108\n",
            "8m 14s (- 12m 22s) (30000 40%) 3.2771\n",
            "9m 37s (- 11m 0s) (35000 46%) 3.1652\n",
            "10m 59s (- 9m 37s) (40000 53%) 3.0741\n",
            "12m 22s (- 8m 15s) (45000 60%) 2.9747\n",
            "13m 45s (- 6m 52s) (50000 66%) 2.9009\n",
            "15m 8s (- 5m 30s) (55000 73%) 2.8307\n",
            "16m 31s (- 4m 7s) (60000 80%) 2.7768\n",
            "17m 54s (- 2m 45s) (65000 86%) 2.7299\n",
            "19m 17s (- 1m 22s) (70000 93%) 2.6752\n",
            "20m 40s (- 0m 0s) (75000 100%) 2.6233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, decoder1) # потери здесь немного меньше чем  с 2 скрытыми слоями. Отдельные слова переводи."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFAvGFDLaRNO",
        "outputId": "204f346a-3f5b-4282-a19d-27fc0daa61e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> это несложно !\n",
            "= it s not hard .\n",
            "< it s a . <EOS>\n",
            "\n",
            "> я не дам вам денег .\n",
            "= i won t give you money .\n",
            "< i don t need you . <EOS>\n",
            "\n",
            "> я забыл оставить официанту чаевые .\n",
            "= i forgot to tip the waiter .\n",
            "< i ve decided to leave the . <EOS>\n",
            "\n",
            "> думаешь том может это наити ?\n",
            "= do you think tom can find it ?\n",
            "< do you think tom will help ? <EOS>\n",
            "\n",
            "> не уходите пока домои .\n",
            "= don t go home yet .\n",
            "< don t leave us . <EOS>\n",
            "\n",
            "> ты не похож на наемного убиицу .\n",
            "= you don t look like a killer .\n",
            "< you re not like your a . . <EOS>\n",
            "\n",
            "> вы солдаты ?\n",
            "= are you soldiers ?\n",
            "< are you going to be ? <EOS>\n",
            "\n",
            "> я был глупым .\n",
            "= i was stupid .\n",
            "< i was was . <EOS>\n",
            "\n",
            "> человек чистит зубы .\n",
            "= the man brushes his teeth .\n",
            "< the is is the . <EOS>\n",
            "\n",
            "> твои дядя сделал эти фотографии не так ли ?\n",
            "= your uncle took these pictures didn t he ?\n",
            "< these these these these these these this isn t ?\n",
            "\n"
          ]
        }
      ]
    }
  ]
}