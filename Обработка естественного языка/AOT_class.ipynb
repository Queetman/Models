{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caf909b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1caf909b",
    "outputId": "7faf1510-b274-4659-968c-5724da81541b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6420,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1853,\n        \"min\": 1,\n        \"max\": 6420,\n        \"num_unique_values\": 6420,\n        \"samples\": [\n          325,\n          1341,\n          6026\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6420,\n        \"samples\": [\n          \"Canada\\u2019s top BDSM doctor says wear a mask, leash, tight leather to prevent spread of COVID-19 #cdnpoli #COVID19 https://t.co/1E7yDlIGBD https://t.co/bffEps28Iy\",\n          \"There are 3 cases considered to have recovered from COVID-19 so our total number of active cases is 23 \\u2013 all remain in quarantine facilities.\\u200b \\u200b Our total number of confirmed cases remains at 1192 which is the number we report to the World Health Organization.\",\n          \"Heard about contact tracing but not sure what it is? It\\u2019s used by health departments to prevent the spread of #COVID19. Learn more: https://t.co/J3Txu3riWr. #SlowtheSpread https://t.co/3f8aEQCTuI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fake\",\n          \"real\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a55c6978-273b-4ae2-ac30-de0e5cda8553\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a55c6978-273b-4ae2-ac30-de0e5cda8553')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a55c6978-273b-4ae2-ac30-de0e5cda8553 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a55c6978-273b-4ae2-ac30-de0e5cda8553');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-1e14bc08-19b8-403f-8e87-a8f8915ea186\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e14bc08-19b8-403f-8e87-a8f8915ea186')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-1e14bc08-19b8-403f-8e87-a8f8915ea186 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1   2  States reported 1121 deaths a small rise from ...  real\n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4   5  Populous states can generate large case counts...  real"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Constraint_Train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e96ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "652e96ee",
    "outputId": "ffa8ddf5-343a-43fd-f68b-26ce2abcc72f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "100%|██████████| 6420/6420 [00:03<00:00, 1659.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "sentences = [word_tokenize(text.lower()) for text in tqdm(df.tweet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45b645",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf45b645",
    "outputId": "8168288d-38f8-490a-d362-8a552f6aec28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'cdc', 'currently', 'reports', '99031', 'deaths', '.', 'in', 'general', 'the', 'discrepancies', 'in', 'death', 'counts', 'between', 'different', 'sources', 'are', 'small', 'and', 'explicable', '.', 'the', 'death', 'toll', 'stands', 'at', 'roughly', '100000', 'people', 'today', '.'], ['states', 'reported', '1121', 'deaths', 'a', 'small', 'rise', 'from', 'last', 'tuesday', '.', 'southern', 'states', 'reported', '640', 'of', 'those', 'deaths', '.', 'https', ':', '//t.co/yasgrtt4ux'], ['politically', 'correct', 'woman', '(', 'almost', ')', 'uses', 'pandemic', 'as', 'excuse', 'not', 'to', 'reuse', 'plastic', 'bag', 'https', ':', '//t.co/thf8gunfpe', '#', 'coronavirus', '#', 'nashville']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf79bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92cf79bd",
    "outputId": "05fffd98-0325-486e-e03b-771faf381768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.8 s, sys: 353 ms, total: 22.1 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "%time model_tweets = Word2Vec(sentences, workers=4, vector_size=300, min_count=3, window=5, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03727acf",
   "metadata": {
    "id": "03727acf"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7aec6",
   "metadata": {
    "id": "3db7aec6"
   },
   "outputs": [],
   "source": [
    "def get_text_embedding(text):\n",
    "    result = []\n",
    "    for word in word_tokenize(text.lower()):\n",
    "        if word in model_tweets.wv:\n",
    "            result.append(model_tweets.wv[word])\n",
    "\n",
    "    if len(result):\n",
    "        result = np.average(result, axis=0)\n",
    "    else:\n",
    "        result = np.zeros(300)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38d873",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f38d873",
    "outputId": "64680db7-af22-4e28-f7e2-f084100fd72b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6420/6420 [00:04<00:00, 1318.73it/s]\n"
     ]
    }
   ],
   "source": [
    "features = [get_text_embedding(text) for text in tqdm(df.tweet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88220e48",
   "metadata": {
    "id": "88220e48"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12c204c",
   "metadata": {
    "id": "d12c204c"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, df.label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da2684",
   "metadata": {
    "id": "c1da2684"
   },
   "outputs": [],
   "source": [
    "#Sklearn_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45983361",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45983361",
    "outputId": "af90a34f-58e6-4e92-b170-71813d8c8d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.92      0.89      0.91       618\n",
      "        real       0.90      0.93      0.92       666\n",
      "\n",
      "    accuracy                           0.91      1284\n",
      "   macro avg       0.91      0.91      0.91      1284\n",
      "weighted avg       0.91      0.91      0.91      1284\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29efb288",
   "metadata": {
    "id": "29efb288"
   },
   "outputs": [],
   "source": [
    "#Sklearn_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183c45c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5183c45c",
    "outputId": "c14ff175-7777-493c-e3f1-b7f05c671a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.92      0.93       618\n",
      "        real       0.93      0.94      0.93       666\n",
      "\n",
      "    accuracy                           0.93      1284\n",
      "   macro avg       0.93      0.93      0.93      1284\n",
      "weighted avg       0.93      0.93      0.93      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21bb067",
   "metadata": {
    "id": "a21bb067"
   },
   "outputs": [],
   "source": [
    "#Sklearn_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb6da7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bbb6da7",
    "outputId": "22374044-10e8-4437-adc9-bf505b9b2af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.92      0.92       618\n",
      "        real       0.92      0.94      0.93       666\n",
      "\n",
      "    accuracy                           0.93      1284\n",
      "   macro avg       0.93      0.93      0.93      1284\n",
      "weighted avg       0.93      0.93      0.93      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range = (1,1))),\n",
    "    ('lda', LatentDirichletAllocation(n_components=10, learning_method='batch',max_iter=10, batch_size=128, random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state = 42, solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172c6ce",
   "metadata": {
    "id": "e172c6ce"
   },
   "outputs": [],
   "source": [
    "#pytorch one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be53c3",
   "metadata": {
    "id": "27be53c3"
   },
   "outputs": [],
   "source": [
    "labels = (df.label == 'real').astype(int).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa424f",
   "metadata": {
    "id": "8eaa424f"
   },
   "outputs": [],
   "source": [
    "token_lists = [word_tokenize(text.lower()) for text in df.tweet]\n",
    "max_len = len(max(token_lists, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a363f35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a363f35",
    "outputId": "a27c5109-4208-4c65-9416-89d5b4c059ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1592"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a276ac24",
   "metadata": {
    "id": "a276ac24"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "fd = Counter([len(tokens) for tokens in token_lists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b26fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "346b26fe",
    "outputId": "f75e4b0f-b4e9-467e-c719-89ece79a94ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20, 178),\n",
       " (25, 174),\n",
       " (22, 170),\n",
       " (18, 170),\n",
       " (19, 168),\n",
       " (21, 168),\n",
       " (16, 163),\n",
       " (17, 162),\n",
       " (15, 160),\n",
       " (23, 156)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693f55d",
   "metadata": {
    "id": "4693f55d"
   },
   "outputs": [],
   "source": [
    "def get_word_embedding(tokens, max_len):\n",
    "    result = []\n",
    "    for i in range(max_len):\n",
    "        if i < len(tokens):\n",
    "            word = tokens[i]\n",
    "            if word in model_tweets.wv:\n",
    "                result.append(model_tweets.wv[word])\n",
    "            else:\n",
    "                result.append(np.zeros(300))\n",
    "        else:\n",
    "            result.append(np.zeros(300))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc73506",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cc73506",
    "outputId": "989f5eb1-598c-44ad-babd-e004916803ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6420/6420 [00:02<00:00, 2884.45it/s]\n"
     ]
    }
   ],
   "source": [
    "features = [get_word_embedding(text, 100) for text in tqdm(token_lists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb3c37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fedb3c37",
    "outputId": "1b7afb5e-d46d-4145-d24d-010c6ad9288e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89a15f",
   "metadata": {
    "id": "1f89a15f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L33a4fQxsbKs",
   "metadata": {
    "id": "L33a4fQxsbKs"
   },
   "source": [
    "Torch one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6640ea8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6640ea8",
    "outputId": "31ef203a-1613-432c-b787-8cf4ffa05767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lstm): LSTM(300, 100)\n",
      "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(300, 100)\n",
    "        self.out = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings, (shortterm, longterm) = self.lstm(x.transpose(0, 1))\n",
    "        prediction = torch.sigmoid(self.out(longterm))\n",
    "        return prediction\n",
    "\n",
    "\n",
    "net = Net()\n",
    "#net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa40e5",
   "metadata": {
    "id": "9dfa40e5"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7ee6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50b7ee6a",
    "outputId": "06bdab3b-ed8e-44e3-86f7-694eb15564d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-02003c1debcb>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  in_data = torch.tensor(X_train).float()\n"
     ]
    }
   ],
   "source": [
    "in_data = torch.tensor(X_train).float()\n",
    "targets = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06c0ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c06c0ae",
    "outputId": "72cfafc3-aa9d-48db-f732-771ad015e446"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4815, 100, 300])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6d46d",
   "metadata": {
    "id": "3bb6d46d"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51535c7b",
   "metadata": {
    "id": "51535c7b"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(in_data, targets, batch_size=16):\n",
    "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
    "        batch_x = in_data[i:i + batch_size]#.cuda()\n",
    "        batch_y = targets[i:i + batch_size]#.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = net(batch_x)\n",
    "        loss = criterion(output.reshape(-1), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa250fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fa250fe",
    "outputId": "577b07e0-24cd-4a0e-a8f0-a2d8fa870664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lstm): LSTM(300, 100)\n",
       "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70adc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf70adc6",
    "outputId": "e31c415d-9617-4023-87d7-7ca7bd3e865d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:18<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:15<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:15<00:00, 18.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:15<00:00, 18.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:15<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:15<00:00, 18.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:18<00:00, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7412, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "  train_one_epoch(in_data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757018d",
   "metadata": {
    "id": "a757018d"
   },
   "outputs": [],
   "source": [
    "in_data_test = torch.tensor(X_test).float()\n",
    "targets_test = torch.tensor(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feca020",
   "metadata": {
    "id": "9feca020"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    #output = net(in_data_test.cuda()).reshape(-1)\n",
    "    output = net(in_data_test).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15aadf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc15aadf",
    "outputId": "ae800999-adef-410f-db9c-b6bb1d0cef96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-c91dd9243900>:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  max(torch.nn.functional.softmax(output))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0010)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(torch.nn.functional.softmax(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789cc84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0789cc84",
    "outputId": "6a852333-93f0-4ed3-8042-ee020d83d21a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960ce1e6",
   "metadata": {
    "id": "960ce1e6"
   },
   "outputs": [],
   "source": [
    "result = (output.cpu() > 0.5) == targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ecbdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e9ecbdc",
    "outputId": "e4386445-846e-4848-d842-9046c126cc11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6504672897196262"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum().item() / len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0561c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23a0561c",
    "outputId": "ebecca9e-5cb4-4ed2-c1e8-7c1397ec1e59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6420/6420 [00:03<00:00, 1732.12it/s]\n"
     ]
    }
   ],
   "source": [
    "features = [get_text_embedding(text) for text in tqdm(df.tweet)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6qTjTojfsgrw",
   "metadata": {
    "id": "6qTjTojfsgrw"
   },
   "source": [
    "Torch two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5a316",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91d5a316",
    "outputId": "db06bb0f-4d58-4bcc-fd5b-045388ad3ddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (out): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.out = nn.Linear(300, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.out(x))\n",
    "\n",
    "\n",
    "net = Net()\n",
    "#net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7bd1a",
   "metadata": {
    "id": "75d7bd1a"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a7032",
   "metadata": {
    "id": "369a7032"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf019a",
   "metadata": {
    "id": "f8bf019a"
   },
   "outputs": [],
   "source": [
    "in_data = torch.tensor(X_train).float()\n",
    "targets = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65134ef",
   "metadata": {
    "id": "f65134ef"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(in_data, targets, batch_size=16):\n",
    "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
    "        batch_x = in_data[i:i + batch_size]#.cuda()\n",
    "        batch_y = targets[i:i + batch_size]#.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = net(batch_x)\n",
    "        loss = criterion(output.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbf0b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bfbf0b4",
    "outputId": "cb09cedf-96fc-4059-87b2-63189908fc17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 621.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6928, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 518.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 390.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6519, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 730.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6421, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1012.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6351, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1116.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6297, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1175.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6254, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 932.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6219, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 878.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6190, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1017.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6165, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 997.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6144, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1051.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6125, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 998.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6108, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1017.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6093, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1064.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6079, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 923.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6067, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 953.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6056, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1456.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6045, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1264.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6036, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 1279.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "  train_one_epoch(in_data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e92cf",
   "metadata": {
    "id": "2b5e92cf"
   },
   "outputs": [],
   "source": [
    "in_data_test = torch.tensor(X_test).float()\n",
    "targets_test = torch.tensor(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a76cf",
   "metadata": {
    "id": "0f4a76cf"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "#    output = net(in_data_test.cuda()).squeeze(1) #havent got cuda. lets use suda)\n",
    "     output = net(in_data_test).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9333b4df",
   "metadata": {
    "id": "9333b4df"
   },
   "outputs": [],
   "source": [
    "result = (output.cpu() > 0.5) == targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345544f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d345544f",
    "outputId": "ee711f73-dba8-4808-b111-2eebe89dcf47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8741433021806854"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum().item() / len(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
